{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2e7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.suppliers import fetch_only_supplier_products\n",
    "from config import SheetName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596835eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Clothing', 'sub_category': 'Bottoms', 'url': 'https://www.krollcorp.com/clothing/bottoms.html'}\n",
      "Status Code: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error fetching Kroll products: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dl4Objects not found in the script.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_only_supplier_products(SheetName.KROLL.value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\services\\suppliers.py:17\u001b[39m, in \u001b[36mfetch_only_supplier_products\u001b[39m\u001b[34m(supplier_name, interval)\u001b[39m\n\u001b[32m     15\u001b[39m df = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m supplier_name == SheetName.KROLL.value:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     df = \u001b[43mscrape_kroll_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m supplier_name == SheetName.SSI.value:\n\u001b[32m     19\u001b[39m     df = scrape_ssi_categories(categories)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:62\u001b[39m, in \u001b[36mscrape_kroll_categories\u001b[39m\u001b[34m(categories)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[32m     61\u001b[39m url = c.get(\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m df = \u001b[43mscrape_kroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m dfs[i] = df\n\u001b[32m     64\u001b[39m sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:49\u001b[39m, in \u001b[36mscrape_kroll\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     47\u001b[39m content = fetch_url(url)\n\u001b[32m     48\u001b[39m products = parse_html_kroll(content)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df = \u001b[43mconvert_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:41\u001b[39m, in \u001b[36mconvert_to_df\u001b[39m\u001b[34m(products)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_df\u001b[39m(products):\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    Convert the list of dictionaries to a pandas DataFrame\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     df = pd.DataFrame(\u001b[43mproducts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mecommerce\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     42\u001b[39m     df.drop([\u001b[33m\"\u001b[39m\u001b[33maffiliation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mitem_list_name\u001b[39m\u001b[33m\"\u001b[39m], axis=\u001b[32m1\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "await fetch_only_supplier_products(SheetName.KROLL.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954b7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from config import SheetName\n",
    "from legacy.util.file import load_json_from_dir\n",
    "from scraper.kroll import scrape_kroll_categories\n",
    "from scraper.rothco import scrape_rothco_categories\n",
    "from scraper.ssi import scrape_ssi_categories\n",
    "from services.db import insert_update_KROLL, insert_update_SSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e255a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Clothing',\n",
       "  'sub_category': 'Bottoms',\n",
       "  'url': 'https://www.krollcorp.com/clothing/bottoms.html'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplier_name = SheetName.KROLL.value\n",
    "\n",
    "categories = load_json_from_dir(f\"{supplier_name}.json\")\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb99e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Clothing', 'sub_category': 'Bottoms', 'url': 'https://www.krollcorp.com/clothing/bottoms.html'}\n",
      "Status Code: 200\n",
      "dl4Objects not found in the script.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mscrape_kroll_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:62\u001b[39m, in \u001b[36mscrape_kroll_categories\u001b[39m\u001b[34m(categories)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[32m     61\u001b[39m url = c.get(\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m df = \u001b[43mscrape_kroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m dfs[i] = df\n\u001b[32m     64\u001b[39m sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:49\u001b[39m, in \u001b[36mscrape_kroll\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     47\u001b[39m content = fetch_url(url)\n\u001b[32m     48\u001b[39m products = parse_html_kroll(content)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df = \u001b[43mconvert_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\ListingBot-backend\\scraper\\kroll.py:41\u001b[39m, in \u001b[36mconvert_to_df\u001b[39m\u001b[34m(products)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_df\u001b[39m(products):\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    Convert the list of dictionaries to a pandas DataFrame\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     df = pd.DataFrame(\u001b[43mproducts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mecommerce\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     42\u001b[39m     df.drop([\u001b[33m\"\u001b[39m\u001b[33maffiliation\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mitem_list_name\u001b[39m\u001b[33m\"\u001b[39m], axis=\u001b[32m1\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df = scrape_kroll_categories(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "183eb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from legacy.util.fetch import fetch_url\n",
    "\n",
    "\n",
    "def parse_html_kroll(html_content):\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Find all product titles (this is a placeholder, you'll need to inspect the actual HTML)\n",
    "    # Example: assuming product titles are in <h2> tags with class 'product-name'\n",
    "    scripts = soup.find_all(\"script\")\n",
    "\n",
    "    for i, scr in enumerate(scripts, 1):\n",
    "        if \"var dl4Objects\" in scr.text:\n",
    "            print(f\"Found the script {i} containing dl4Objects.\")\n",
    "            script = scr.text.strip()\n",
    "            print(script[:1000])  # Print the first 1000 characters for inspection\n",
    "            break\n",
    "    else:\n",
    "        script = None\n",
    "\n",
    "    # if scripts is None or len(scripts) < 11:\n",
    "    #     print(\"No scripts found.\")\n",
    "    #     return None\n",
    "\n",
    "    # script = scripts.strip()\n",
    "    # script = scripts[11].text.strip()\n",
    "    # print(script[:1000])  # Print the first 1000 characters of the script for inspection\n",
    "\n",
    "\n",
    "    # Use regular expression to find the dl4Objects list\n",
    "    match = re.search(r\"var dl4Objects = (\\[.*?\\]);\", script, re.DOTALL)\n",
    "    print(match)\n",
    "    if match:\n",
    "        dl4Objects_str = match.group(1)\n",
    "        # Convert the string representation of the list to an actual list\n",
    "        dl4Objects = eval(dl4Objects_str)\n",
    "        # print(dl4Objects)\n",
    "        print(f\"Found {len(dl4Objects)} objects.\")\n",
    "        return dl4Objects\n",
    "    else:\n",
    "        print(\"dl4Objects not found in the script.\")\n",
    "\n",
    "\n",
    "def convert_to_df(products):\n",
    "    \"\"\"\n",
    "    Convert the list of dictionaries to a pandas DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(products[1][\"ecommerce\"][\"items\"])\n",
    "    df.drop([\"affiliation\", \"item_list_name\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def scrape_kroll(url):\n",
    "    content = fetch_url(url)\n",
    "    products = parse_html_kroll(content)\n",
    "    df = convert_to_df(products)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Clothing', 'sub_category': 'Bottoms', 'url': 'https://www.krollcorp.com/clothing/bottoms.html'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Found the script 8 containing dl4Objects.\n",
      "if (window.ga4AllowServices) {\n",
      "            window.dataLayer = window.dataLayer || [];\n",
      "                        var dl4Objects = [{\"pageName\":\"Bottoms - Clothing\",\"pageType\":\"category\"},{\"ecommerce\":{\"items\":[{\"item_name\":\"Women's Distinction 4-Pocket Pants\",\"affiliation\":\"Main Website - Main Website Store - Default Store View\",\"item_id\":\"ELB-E949XLCN\",\"price\":67.85,\"item_brand\":\"Elbeco\",\"item_category\":\"Clothing\",\"item_category2\":\"Bottoms\",\"item_list_name\":\"Clothing\\/Bottoms\",\"item_list_id\":\"16\",\"index\":1},{\"item_name\":\"XTU PANT\",\"affiliation\":\"Main Website - Main Website Store - Default Store View\",\"item_id\":\"5-745541863634\",\"price\":155.77,\"item_brand\":\"5.11 Tactical\",\"item_category\":\"Clothing\",\"item_category2\":\"Bottoms\",\"item_list_name\":\"Clothing\\/Bottoms\",\"item_list_id\":\"16\",\"index\":2},{\"item_name\":\"Command Serge Pants\",\"affiliation\":\"Main Website - Main Website Store - Default Store View\",\"item_id\":\"FLC-F138200\",\"price\":46.15,\"item_brand\":\"Flying Cross\",\"item_category\":\"Clothing\",\"i\n",
      "<re.Match object; span=(110, 3973), match='var dl4Objects = [{\"pageName\":\"Bottoms - Clothing>\n",
      "Found 2 objects.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n",
      "<string>:1: SyntaxWarning: invalid escape sequence '\\/'\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for i, c in enumerate(categories, 1):\n",
    "    print(c)\n",
    "    url = c.get(\"url\")\n",
    "    df = scrape_kroll(url)\n",
    "    dfs[i] = df\n",
    "    sleep(1)\n",
    "    # break  # Uncomment for debugging single category\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5ed09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-listing-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
